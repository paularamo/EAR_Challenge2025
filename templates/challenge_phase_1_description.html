<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Challenge Objectives and Details</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            font-size: 16px;
            line-height: 1.5;
        }
        h1, h2, h3 {
            font-size: 20px;
            font-weight: bold;
            margin-top: 1em;
        }
        p, ul {
            margin: 0.5em 0;
        }
        ul {
            padding-left: 1.5em;
        }
        li {
            margin: 0.3em 0;
        }
        a {
            color: #0066cc;
            text-decoration: none;
        }
        a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>Challenge Objectives</h1>
    <p>Participants will:</p>
    <ul>
        <li>Develop state-of-the-art models for elderly action recognition using publicly available datasets.</li>
        <li>Showcase innovative techniques for data curation and transfer learning.</li>
        <li>Contribute to a growing body of research that addresses real-world challenges in elderly care.</li>
    </ul>

    <h2>Key Dates</h2>
    <ul>
        <li><strong>Challenge Launch:</strong> January 10, 2025</li>
        <li><strong>Submission Deadline:</strong> February 15, 2025</li>
        <li><strong>Winners Announcement:</strong> February 20, 2025, at the virtual AI, Machine Learning, and Computer Vision Meetup</li>
    </ul>

    <h2>Model Development</h2>
    <p>Participants are encouraged to explore and leverage state-of-the-art human action recognition models without limitations. Creativity and originality in model architecture and training methodology are strongly encouraged.</p>

    <h2>Dataset</h2>
    <p>To mitigate overfitting and promote generalization, participants could build training datasets using publicly available resources such as:</p>
    <ul>
        <li><a href="https://etri.org/Activity3D" target="_blank">ETRI-Activity3D</a></li>
        <li><a href="https://muvim.org" target="_blank">MUVIM</a></li>
        <li><a href="https://toyotasmarthome.com" target="_blank">ToyotaSmartHome</a></li>
    </ul>
    <p>Note that some datasets require submitting a request before downloading. Participants are not restricted to these datasets and are welcome to curate extensive datasets, combining multiple sources. A detailed report outlining the datasets used and their preparation and curation processes is mandatory.</p>

    <h2>Data Curation and Categorization</h2>
    <p>Participants must group activities into the following categories for efficient organization and analysis. Model output should display both categories and activities.</p>
    <ul>
        <li><strong>Locomotion and Posture Transitions:</strong> Walking, sitting down/standing up, getting up/lying down, exercising, looking for something</li>
        <li><strong>Object Manipulation:</strong> Spreading bedding/folding bedding, wiping table, cleaning dishes, cooking, vacuuming</li>
        <li><strong>Hygiene and Personal Care:</strong> Washing hands, brushing teeth, taking medicine</li>
        <li><strong>Eating and Drinking</strong></li>
        <li><strong>Communication and Gestures:</strong> Talking, phone calls, waving a hand, shaking hands, hugging</li>
        <li><strong>Leisure and Stationary Actions:</strong> Reading, watching TV</li>
    </ul>

    <h2>Supporting Materials</h2>
    <p>Voxel51â€™s <a href="https://voxel51.com/fiftyone/" target="_blank">FiftyOne</a> tool will assist participants in effectively curating, categorizing, and visualizing datasets. Tutorials and examples will be provided at the challenge launch.</p>
</body>
</html>
